# Data Science Application Domains

Companies know that if they can't measure something, they're unable to improve it

So, it's essential to start capturing data, so you can apply algorithms and analytics to it

If you are capturing data, archive your old data

Companies can leverage the amount of data they have in many ways. However, all organizations use data science for the same reason: to discover optimum solution to existing problems

### Recommendation Engine

A **Recommendation Engine** is a common application of Data Science

Companies, like Netflix, Amazon and Spotify, use algorithms to make specific recommendations derived from customer preferences and historical behaviour


### Personal Assistants

**Personal Assistants**, like Siri, use Data Science to devise answers to the infinite numbers of questions the user may ask

The ultimate purpose of analytics is to communicate findings to the concerned who might use these insights to formulate policy or strategy

Analytics summarize findings in tables and plots. The data scientist should then use the insights to build the narative to communicate findings

In academia, the final deliverable is in the form of essays and reports

In consulting and business, the final deliverable takes on serveral forms. It can be a small documents of fewer than 1500 words illustrated with tables and plot or it could be a comprehensive document comprising several hundred pages


### Glossary Terms

* **Case Study**: In-depth analysis of an instance of a chosen subject to draw insights that inform theory, practice or decision-making

* **Data Strategy**: A plan that outlines how an organization will collect, manage and use data to achieve its goal


# Careers and Recruiting in Data Science

## How can someone become a data scientist?

The first skill you need is how to program, at least, have some **computational thinking**

Secondly, you need to know some **algebra**, **calculus**, **probability**, **statistics** and **databases**

But then, as you go further up in the fields, then you need to know a lot of **computer science theory**


## The Report Structure

Before starting the analysis, think about the structure of the report. The structure of the report depends on the length of the document

A brief report is more to the point and presents a summary of key findings. Brief reports were drafted as commentaries on current trends and development that attracted public or media attention

A detailed report incrementally builds the argument and contains details about other relevant works. Detailed and comprehensive reports offered a critical review of the subject matter with extensive data analysis and commentary

Even if you expect the report to be brief, sporting five or fewer pages, I recommend that the deliverable follow a prescribed format, including the cover page, table of contents, executive summary, detailed contents, acknowledgments, references and appendices

At a minimum, the cover page should include the title of the report, names of authors, their affiliations and contacts, the name of the institutional publisher and the data of publication

Even for a short document, It's recommended an *abstract* or an *executive summary*

An *introductory section* is always helpful in setting up the problem for the reader who might be new to the topic and who might need to be gently introduced to the subject matter

In the *methodology section*, you introduce the research methods and data sources you used for the analysis. If you have collected new data, explain the data collection

The results section is where you present your empirical findings. Starting with descriptive statistics and illustrative graphics,  you will move toward formally testing your hypothesis

The results section is followed by the discussion section, where you craft your main arguments by building on the results you have presented earlier

# Understanding Data

## Data Types

### Structured Data

Structured data is objective facts and numbers that can be collecte, exported, stored and organized in typical databases

* It has a well-defined structure

* It can be stored in well-defined schemas

* In many cases, it can be represented in a tabular manner with rows and columns

* Some examples are:
    * SQL Databases
    * Online Transaction Processing
    * Spreadsheets
    * Online forms
    * Sensors GPS and RFID
    * Network and Web server logs


### Semi-structured Data

* It has some organizational properties but lacks a fixed or rigid schema

* It cannot be stored in the form of rows and columns as in databases

* It contains tags and elements, or metadata, which is used to group data and organize it in a hierarchy

* Some examples are:
    * Emails
    * XML
    * Binary Executables
    * TCP/IP packets
    * Zipped files
    * Integration of data


### Unstructured Data

* Data that does not have an easily identifiable structure

* It cannot be stored in a mainstream relational database in the form of rows and columns

* It does not follow any particular format, sequence or rules

* It can be stored in files and documents for manual analysis or in NoSQL databases

* Some examples are:
    * Web pages
    * Social media feeds
    * Images
    * Videos
    * Audios
    * PDFs


## Data Sources

### Flat files

* It stores data in plain text format

* Each line or row is one record

* Each value is separated by a delimiter

* All of the data in a flat file maps to a single table

* Examples:
    * CSV
    * TSV
    * Spreadsheet: it is a special type since it can have multiple worksheets and each one of them map to a different table


### XML files

* It contain data value that are identified or marked up using tags

* It can support complex data structures

* Common uses:
    * Online surveys
    * Bank statements

## Web Scraping

* It's used to extract relevant data from unstructured sources

* Also known as **Screen scraping**, **Web harvesting** and **Web data extraction**

* It's possible to download specific data from web pages based on defined parameters

* Some Web Scraping tools are:
    * BeautifulSoup
    * Scrapy
    * Pandas
    * Selenium

## Data Streams and Feeds

* Aggregating streams of data flowing from instruments, IoT devices and applications, GPS data from cars, computer programs